MODULE: bsplyne.parallel_utils
==============================
Documentation for module bsplyne.parallel_utils

GLOBAL FUNCTIONS:
~~~~~~~~~~~~~~~~~~
  >>> parallel_blocks_inner(
    funcs: Iterable[Callable],
    all_args: Iterable[tuple],
    num_blocks: int,
    verbose: bool,
    pbar_title: str,
    disable_parallel: bool,
    shared_mem_last_arg: Optional[numpy.ndarray]
) -> list
      Execute a list of functions with their corresponding argument tuples, optionally in parallel blocks.
      
      This function performs the actual execution of tasks either sequentially or in parallel,
      depending on the `disable_parallel` flag. When running in parallel, the tasks are divided into
      `num_blocks` groups (blocks), each executed by a separate worker process. Intermediate results
      are temporarily saved to disk as `.npy` files to limit memory usage and are reloaded sequentially
      after all processes complete.
      
      Parameters
      ----------
      funcs : Iterable[Callable]
          List of functions to execute. Must have the same length as `all_args`.
          Each function is called as `func(*args)` for its corresponding argument tuple.
      all_args : Iterable[tuple]
          List of tuples, each containing the arguments for the corresponding function in `funcs`.
      num_blocks : int
          Number of parallel blocks (i.e., worker processes) to use when `disable_parallel` is False.
          Determines how many subsets of tasks will be distributed among processes.
      verbose : bool
          If True, enables progress bars and displays information about block processing and result gathering.
      pbar_title : str
          Title prefix used for progress bar descriptions.
      disable_parallel : bool
          If True, all tasks are executed sequentially in the current process. If False, tasks are divided
          into blocks and processed in parallel using a multiprocessing pool.
      shared_mem_last_arg : Union[np.ndarray, None]
          Optional NumPy array placed in shared memory and appended automatically as the last argument
          of each task. This is useful for sharing large read-only data (e.g., images, meshes) without
          duplicating memory across processes.
      
      Returns
      -------
      list
          List of results obtained from applying each function to its corresponding argument tuple,
          preserving the original task order.
      
      Notes
      -----
      - **Sequential mode:** if `disable_parallel` is True, all functions are executed in the current
        process with an optional progress bar.
      - **Parallel mode:**
          * The tasks are split into `num_blocks` subsets.
          * Each subset is processed by a separate worker via `multiprocessing.Pool`.
          * Each worker writes its results as `.npy` files inside a temporary subfolder.
          * After all workers complete, results are reloaded in the original order, and temporary files
            and folders are deleted.
      - **Shared memory:** if `shared_mem_last_arg` is provided, it is stored once in shared memory
        and accessible by all workers, avoiding redundant copies of large data arrays.
      - Compatible with both standard Python terminals and Jupyter notebooks (adaptive progress bars).
      - Intended for internal use by higher-level orchestration functions such as `parallel_blocks()`.

  >>> parallel_blocks(
    funcs: Union[Callable, Iterable[Callable]],
    all_args: Optional[Iterable[tuple]] = None,
    num_blocks: Optional[int] = None,
    verbose: bool = True,
    pbar_title: str = 'Processing blocks',
    disable_parallel: bool = False,
    est_proc_cost: float = 0.5,
    shared_mem_last_arg: Optional[numpy.ndarray] = None
) -> list
      Execute a set of independent tasks sequentially or in parallel, depending on their estimated cost.
      
      The function evaluates the runtime of the first task to decide whether parallelization is worth
      the overhead of process creation. If parallel execution is deemed beneficial, the remaining tasks
      are distributed across several blocks processed in parallel. Otherwise, all tasks are executed
      sequentially. This strategy is especially useful when task runtimes are variable or short compared
      to process spawning costs.
      
      Parameters
      ----------
      funcs : Union[Callable, Iterable[Callable]]
          Function or list of functions to execute.
          - If a single function is provided, it will be applied to each argument tuple in `all_args`.
          - If a list of functions is provided, it must have the same length as `all_args`, allowing each
            task to use a distinct callable.
      all_args : Union[Iterable[tuple], None], optional
          Iterable of tuples containing the positional arguments for each function call.
          If the function takes no arguments, set `all_args` to `None` (defaults to empty tuples).
      num_blocks : Union[int, None], optional
          Number of parallel blocks (i.e., worker processes) to use. Defaults to half the number of CPU cores.
          A value of 1 forces sequential execution.
      verbose : bool, optional
          If True, displays timing information and progress bars. Default is True.
      pbar_title : str, optional
          Title prefix displayed in the progress bar. Default is "Processing blocks".
      disable_parallel : bool, optional
          If True, forces all computations to run sequentially regardless of estimated profitability.
          Default is False.
      est_proc_cost : float, optional
          Estimated process creation cost in seconds. Used to determine whether parallelization
          will yield a net speedup. Default is 0.5 s.
      shared_mem_last_arg : Union[np.ndarray, None], optional
          Shared-memory NumPy array to be appended automatically as the last argument in each task.
          This allows tasks to read from a large, read-only array without duplicating it in memory.
          Default is None.
      
      Returns
      -------
      list
          List of results, one per task, preserving the input order.
      
      Notes
      -----
      - The first task is executed sequentially to estimate its runtime.
      - Parallelization is enabled only if the estimated time saved exceeds the cost of process creation.
      - When parallel mode is used, tasks are executed in blocks, and intermediate results are stored
        temporarily on disk to limit memory usage, then reloaded and combined sequentially.
      - Compatible with Jupyter progress bars (`tqdm.notebook`).
